= How to Design a Data Ingestion and Aggregation Application with Cyoda?

== 1. What is the requirement?

We need to build an application that ingests data from external systems (data sources), processes it, and aggregates the data into a report.

== 2. What is the business domain?

For this example, we'll focus on the accounting domain. The application will ingest data about employee expenses and aggregate that data into a report.

== 3. What is the entry point?

The entry point will be a scheduled job that triggers the ingestion of data and the generation of a report.

== 4. What are the main entities?

Let's define the JSON schemas for the main entities:

=== `employee_expense`

This entity represents the data collected from the data sources. Below is a sample schema for `employee_expense`:

[source,json]
----
{
  "employeeName": "John Doe",
  "department": "Sales",
  "position": "Sales Manager",
  "expenseDate": "2024-10-05",
  "expenseCategory": "Travel",
  "expenseDescription": "Flight to client meeting",
  "amount": 250.00,
  "projectName": "Client Acquisition",
  "quarter": "Q4",
  "year": 2024
}
----

=== `expense_report`

This entity represents the aggregated report that will be saved after data analysis. The structure of `expense_report` is as follows:

[source,json]
----
{
  "report": "Summary of expenses"
}
----

=== `expense_report_job`

This entity represents a job to ingest data and generate a report. It tracks the date, associated requests, and the status of report generation:

[source,json]
----
{
  "date": "2024-10-22",
  "requestIds": [
    "7fb76bd5-43d3-40be-a45e-ecb1180f2313", 
    "de81dfbd-4d29-40c2-a90e-89d1180f2312"
  ],
  "finishedRequestIds": [
    "7fb76bd5-43d3-40be-a45e-ecb1180f2313"
  ],
  "reportId": "a02e184a-92eb-11ef-b7d3-ca6fd3f80374"
}
----

== 5. What are the workflows for the entities?

=== `employee_expense`

This entity is the foundational data model for ingestion. It does not require a custom workflow.

=== `expense_report`

This entity represents the final report generated after analyzing the data. There is no custom workflow needed for this entity.

=== `expense_report_job`

This entity follows the workflow below:

[IngestDataFromSystem1] ---> [IngestDataFromSystem2] ---> [ValidateDataIngestion] ---> [GenerateReport1] ---> [SendReport]

== 6. What are the required integrations?

We need to set up connections to both data sources (System 1 and System 2). The data ingested from these sources must be mapped to the `employee_expense` entity. Appropriate transformation or validation rules should be applied as part of the ingestion process.

== 7. Is there any data aggregation?

Yes, we will use **Trino** (a SQL query engine) to perform data aggregation for the report. Trino will aggregate the expense data into a format suitable for reporting and analysis.
